{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["'''\n","2. 강의의 RNN을 이용한 로이터 뉴스 카테고리 분류 실습에서 모델을 설계하고 학습하는 프로그램을 작성하고, 프로그램 소스와 실행 결과 화면을 캡처하여 제출하시오.\n","'''\n","\n","# 필요한 라이브러리 import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow의 Keras API 함수 import\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# load_data() : 로이터 데이터셋을 로드하고 학습 데이터셋과 훈련 데이터셋으로 반환\n","# - num_words : 빈도 수\n","# - test_split : 테스트 데이터셋 비율\n","(x_train, y_train), (x_test, y_test) = # <==Insert code here\n","\n","print(\"학습 데이터셋 :\", len(x_train))\n","print(\"테스트 데이터셋 :\", len(x_test))\n","\n","# max : 원소의 최댓값 반환\n","print(\"카테고리 수 :\", np.max(y_train) + 1)\n","\n","# sequence.pad_sequences() : 시퀀스 데이터의 패딩 수행\n","# - maxlen : 시퀀스 데이터의 최대 길이\n","x_train = # <==Insert code here\n","x_test = # <==Insert code here\n","\n","# to_categorical() : 정수 형태의 클래스 레이블을 원-핫 인코딩된 벡터로 변환\n","y_train = # <==Insert code here\n","y_test = # <==Insert code here\n","\n","model = Sequential()\n","\n","# Embedding Layer 생성\n","# - 첫 번째 인자 : 입력 단어 수\n","# - 두 번째 인자 : 출력 임베딩 벡터의 차원\n","embedding = Embedding(1000, 100)\n","\n","# Simple RNN Layer 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - activation : 활성화 함수\n","#    - tanh : 하이퍼볼릭 탄젠트 함수\n","# - return_sequences\n","#    - True : 각 시점의 출력 반환\n","#    - False : 마지막 시점의 출력만 반환\n","simple_rnn_1 = # <==Insert code here\n","\n","# Simple RNN Layer 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - activation : 활성화 함수\n","#    - tanh : 하이퍼볼릭 탄젠트 함수\n","# - return_sequences\n","#    - True : 각 시점의 출력 반환\n","#    - False : 마지막 시점의 출력만 반환\n","simple_rnn_2 = # <==Insert code here\n","\n","# Hidden Layer 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - activation : 활성화 함수\n","#    - relu : ReLU 함수\n","hidden_layer = # <==Insert code here\n","\n","# Output Layer 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - activation : 활성화 함수\n","#    - softmax : 소프트맥스 함수\n","output_layer = # <==Insert code here\n","\n","# add() : 모델에 Layer 추가\n","model.add(embedding)\n","model.add(simple_rnn_1)\n","model.add(simple_rnn_2)\n","model.add(hidden_layer)\n","model.add(output_layer)\n","\n","# summary() : 모델의 구조 및 매개 변수(파라미터)에 대한 정보를 요약\n","model.summary()\n","\n","# compile() : 모델 학습 과정 설정\n","# - optimizer : 손실 함수을 통해 얻은 오차를 줄여주기 위해 모델을 업데이트하는 방법\n","#   - adam : Adam\n","# - loss : 손실 함수(실제 값과 예측 값 사이의 오차에 대한 식)\n","#   - categorical_crossentropy : (다항 분류) 교차 엔트로피 오차 함수\n","# - metrics : 성능 지표\n","#   -  accuracy : 정확도\n","# <==Insert code here\n","\n","# EarlyStopping : 학습 중인 모델을 조기 중단\n","# - monitor : 모니터링할 지표\n","# - patience : 지정된 지표가 개선되지 않는 에포크 수\n","early_stopping = # <==Insert code here\n","\n","# fit() : 모델 학습\n","# - 첫 번째 인자 : 입력 데이터\n","# - 두 번째 인자 : 결과 데이터\n","# - batch_size : 한 번에 학습할 때 사용하는 데이터 개수\n","# - epochs : 학습 데이터 반복 횟수\n","# - validation_data : 검증 데이터셋\n","# - callbacks : 학습 중에 사용할 콜백\n","history = # <==Insert code here"],"metadata":{"id":"Vcl_4Y33uCpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate() : 모델 평가 지표 반환\n","results = model.evaluate(x_test, y_test)\n","print('테스트 손실 :', results[0])\n","print('테스트 정확도 :', results[1])\n","\n","# 학습 데이터셋과 검증 데이터셋의 정확도와 오차\n","accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = np.arange(16)\n","\n","# 정확도 그래프\n","plt.plot(epochs, accuracy, \"b--\", label='train_accuracy') # 학습 정확도 표시\n","plt.plot(epochs, val_accuracy, \"b\", label='validation _accuracy') # 검증 정확도 표시\n","plt.title('Training and Validation Accuracy') # 제목\n","plt.legend() # 범례\n","plt.grid() # 그리드(격자)\n","plt.xlabel('epochs') # x축 레이블\n","plt.ylabel('accuracy') # y축 레이블\n","plt.show() # 그래프 출력\n","\n","# 오차 그래프\n","plt.plot(epochs, loss, \"r--\", label='train_loss') # 학습 오차 표시\n","plt.plot(epochs, val_loss, \"r\", label='validation_loss') # 검증 오차 표시\n","plt.title('Training and Validation Loss') # 제목\n","plt.legend() # 범례\n","plt.grid() # 그리드(격자)\n","plt.xlabel('epochs') # x축 레이블\n","plt.ylabel('loss') # y축 레이블\n","plt.show() # 그래프 출력"],"metadata":{"id":"rFwY3-OJvTCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","3. 강의의 LSTM을 이용한 영화 리뷰 분류 실습에서 모델을 설계하고 학습하는 프로그램을 작성하고, 프로그램 소스와 실행 결과 화면을 캡처하여 제출하시오.\n","'''\n","\n","# 필요한 라이브러리 import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow의 Keras API 함수 import\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# load_data() : imdb 데이터셋을 로드하고 학습 데이터셋과 훈련 데이터셋으로 반환\n","# - num_words : 빈도 수\n","(x_train, y_train), (x_test, y_test) = # <==Insert code here\n","\n","print(\"학습 데이터셋 :\", len(x_train))\n","print(\"테스트 데이터셋 :\", len(x_test))\n","\n","# max : 원소의 최댓값 반환\n","print(\"카테고리 수 :\", np.max(y_train) + 1)\n","\n","# sequence.pad_sequences() : 시퀀스 데이터의 패딩 수행\n","# - maxlen : 시퀀스 데이터의 최대 길이\n","x_train = # <==Insert code here\n","x_test = # <==Insert code here\n","\n","# CNN 모델 정의\n","model = Sequential()\n","\n","# Embedding Layer 생성\n","# - 첫 번째 인자 : 입력 단어 수\n","# - 두 번째 인자 : 출력 임베딩 벡터의 차원\n","embedding = # <==Insert code here\n","\n","# 1차원 합성곱 층 생성\n","# - 첫 번째 인자 : 적용할 커널 수\n","# - kernel_size : 커널의 크기\n","# - activation : 활성화 함수\n","#    - relu : ReLU 함수\n","convolutional_layer = # <==Insert code here\n","\n","# 1차원 Max Pooling 층 생성\n","# - pool_size : 풀링 윈도우 크기\n","max_pooling_1d = # <==Insert code here\n","\n","# 첫 번째 LSTM 층 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - return_sequences\n","#    - True : 각 시점의 출력 반환\n","#    - False : 마지막 시점의 출력만 반환\n","lstm_1 = # <==Insert code here\n","\n","# 두 번째 LSTM 층 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - return_sequences\n","#    - True : 각 시점의 출력 반환\n","#    - False : 마지막 시점의 출력만 반환\n","lstm_2 = # <==Insert code here\n","\n","# 출력층 생성\n","# - 첫 번째 인자 : 출력 차원\n","# - activation : 활성화 함수\n","#    - sigmoid : 시그모이드 함수\n","output_layer = # <==Insert code here\n","\n","# add() : 모델에 Layer 추가\n","model.add(embedding)\n","model.add(convolutional_layer)\n","model.add(Dropout(0.5))\n","model.add(max_pooling_1d)\n","model.add(lstm_1)\n","model.add(lstm_2)\n","model.add(output_layer)\n","\n","# summary() : 모델의 구조 및 매개 변수(파라미터)에 대한 정보를 요약\n","model.summary()\n","\n","# compile() : 모델 학습 과정 설정\n","# - optimizer : 손실 함수을 통해 얻은 오차를 줄여주기 위해 모델을 업데이트하는 방법\n","#   - adam : Adam\n","# - loss : 손실 함수(실제 값과 예측 값 사이의 오차에 대한 식)\n","#   - binary_crossentropy : 교차 엔트로피 오차 함수\n","# - metrics : 성능 지표\n","#   -  accuracy : 정확도\n","# <==Insert code here\n","\n","# EarlyStopping : 학습 중인 모델을 조기 중단\n","# - monitor : 모니터링할 지표\n","# - patience : 지정된 지표가 개선되지 않는 에포크 수\n","early_stopping = # <==Insert code here\n","\n","# fit() : 모델 학습\n","# - 첫 번째 인자 : 입력 데이터\n","# - 두 번째 인자 : 결과 데이터\n","# - batch_size : 한 번에 학습할 때 사용하는 데이터 개수\n","# - epochs : 학습 데이터 반복 횟수\n","# - validation_split : 검증 데이터셋 비율\n","# - callbacks : 학습 중에 사용할 콜백\n","history = # <==Insert code here"],"metadata":{"id":"WOi7iYaosorW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate() : 모델 평가 지표 반환\n","results = # <==Insert code here\n","print('테스트 손실 :', results[0])\n","print('테스트 정확도 :', results[1])\n","\n","# 학습 데이터셋과 검증 데이터셋의 정확도와 오차\n","accuracy = # <==Insert code here\n","val_accuracy = # <==Insert code here\n","loss = # <==Insert code here\n","val_loss = # <==Insert code here\n","\n","epochs = np.arange(8)\n","\n","# 정확도 그래프\n","plt.plot(epochs, accuracy, \"b--\", label='train_accuracy') # 학습 정확도 표시\n","plt.plot(epochs, val_accuracy, \"b\", label='validation _accuracy') # 검증 정확도 표시\n","plt.title('Training and Validation Accuracy') # 제목\n","plt.legend() # 범례\n","plt.grid() # 그리드(격자)\n","plt.xlabel('epochs') # x축 레이블\n","plt.ylabel('accuracy') # y축 레이블\n","plt.show() # 그래프 출력\n","\n","# 오차 그래프\n","plt.plot(epochs, loss, \"r--\", label='train_loss') # 학습 오차 표시\n","plt.plot(epochs, val_loss, \"r\", label='validation_loss') # 검증 오차 표시\n","plt.title('Training and Validation Loss') # 제목\n","plt.legend() # 범례\n","plt.grid() # 그리드(격자)\n","plt.xlabel('epochs') # x축 레이블\n","plt.ylabel('loss') # y축 레이블\n","plt.show() # 그래프 출력"],"metadata":{"id":"SKNCY4U7v9xI"},"execution_count":null,"outputs":[]}]}